{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": " DeepSmote Export.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW6CUKdlodBN"
      },
      "source": [
        "# Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9KeV1R_J1VT"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vYGjdXUnoCn"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision.datasets import ImageFolder, DatasetFolder\n",
        "import torchvision\n",
        "import sys\n",
        "\n",
        "\n",
        "def seed_libraries(SEED=42):\n",
        "    # Python seeds\n",
        "    random.seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    # Torch seeds\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "SEED=42\n",
        "seed_libraries(SEED=SEED)\n",
        "\n",
        "\n",
        "# set computation device\n",
        "runtime = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f\"Computation device: {runtime}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OzPg7Ft8KaJ"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "data_file_name = 'WaferImages_en_8'\n",
        " \n",
        "\n",
        "PATH_DATA = f'/content/drive/MyDrive/DViP/data/{data_file_name}.zip'\n",
        " \n",
        "!unzip $PATH_DATA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6MUMqfd7dvi"
      },
      "source": [
        "class ImageFolderManual(ImageFolder):\n",
        "     def find_classes(self, dir):\n",
        "        \"\"\"\n",
        "        Finds the class folders in a dataset.\n",
        "        Args:\n",
        "            dir (string): Root directory path.\n",
        "        Returns:\n",
        "            tuple: (classes, class_to_idx) where classes are relative to (dir), and class_to_idx is a dictionary.\n",
        "        Ensures:\n",
        "            No class is a subdirectory of another.\n",
        "        \"\"\"\n",
        "        if sys.version_info >= (3, 5):\n",
        "            # Faster and available in Python 3.5 and above\n",
        "            classes = [d.name for d in os.scandir(dir) if d.is_dir() and (d.name == \"circle\" or d.name == \"splinter\")]\n",
        "        else:\n",
        "            classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
        "        classes.sort()\n",
        "        class_to_idx = {'circle': 0, 'splinter': 1}\n",
        "        #class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "        return classes, class_to_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shtLEdl8CTTc"
      },
      "source": [
        "image_dataset = ImageFolderManual(f'/content/{data_file_name}')\n",
        "print(\"Imageset Length: \" + str(len(image_dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkFVT7K2popy"
      },
      "source": [
        "shuffle = True\n",
        "random_state = 42\n",
        "\n",
        "# Prepare Dataset into Train and Val and and Test (60:20:20)\n",
        "\n",
        "dataset_size = len(image_dataset)\n",
        "indices = list(range(dataset_size))\n",
        "\n",
        "train_val_indices, test_indices = train_test_split(indices,\n",
        "                                                    stratify=[image_dataset.targets[i] for i in indices],\n",
        "                                                    test_size=0.20,\n",
        "                                                    shuffle=shuffle,\n",
        "                                                   random_state=random_state,\n",
        "                                                   )\n",
        "\n",
        "train_indices, val_indices = train_test_split(train_val_indices,\n",
        "                                            stratify=[image_dataset.targets[i] for i in train_val_indices],\n",
        "                                            test_size=0.25,\n",
        "                                            shuffle=shuffle,\n",
        "                                            random_state=random_state,\n",
        "                                            )\n",
        "\n",
        "train_subset = Subset(image_dataset, train_indices)\n",
        "val_subset = Subset(image_dataset, val_indices)\n",
        "test_subset = Subset(image_dataset, test_indices)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtJ7E3NtqQ2a"
      },
      "source": [
        "print(len(train_subset))\n",
        "print(len(val_subset))\n",
        "print(len(test_subset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yPykdl3nKQi"
      },
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "                                      transforms.Resize((256,256)),\n",
        "                                      transforms.Grayscale(num_output_channels=1),\n",
        "                                      transforms.ToTensor()\n",
        "                                      ])\n",
        "\n",
        "X_train = [train_transform(img[0]) for img in image_dataset]\n",
        "X_train = [np.array(img) for img in X_train]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARZIHA3P0KX5"
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "X_train = X_train.reshape(X_train.shape[0],-1)\n",
        "print(X_train.shape)\n",
        "\n",
        "# The DeepSMOTE researches saved the loaded images in a .txt file. Thus, the same approach was used.\n",
        "np.savetxt('/content/splinter_and_circle_256.txt', X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxFWFHFS5nP6"
      },
      "source": [
        "labelset = []\n",
        "for img in image_dataset:\n",
        "  labelset.append(img[1])\n",
        "print(labelset)\n",
        "labelset = np.array(labelset)\n",
        "print(labelset.shape)\n",
        "np.savetxt('/content/splinter_and_circle_256_label.txt', labelset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cKwQCnKc3ze"
      },
      "source": [
        "from collections import Counter\n",
        "print(Counter(labelset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-VKVhF8PGBi"
      },
      "source": [
        "# The given orginal DeepSMOTE-sourcecode is more extensive.\n",
        "# I cleaned up the codeblock down to what is actually used. \n",
        "# Of course, also many things were changed to fit this project and also to reduce the complexity of this experiment.\n",
        "\n",
        "import collections\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import time\n",
        "import os\n",
        "\n",
        "print(torch.version.cuda) #10.1\n",
        "t3 = time.time()\n",
        "##############################################################################\n",
        "\"\"\"args for AE\"\"\"\n",
        "\n",
        "args = {}\n",
        "args['lambda'] = 0.0001       # hyper param for weight decay\n",
        "args['lr'] = 0.0001           # learning rate for Adam optimizer \n",
        "args['epochs'] = 200          # how many epochs to run for\n",
        "args['batch_size'] = 4        # batch size for SGD\n",
        "args['train'] = True          # train networks if True, else load networks from\n",
        "\n",
        "##############################################################################\n",
        "\n",
        "batch_size = args['batch_size']\n",
        "\n",
        "## create encoder model and decoder model\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        ###########\n",
        "        ### HEXANET START\n",
        "        ###########\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=7, stride=2, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=32)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=2, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(num_features=64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(num_features=128)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.bn4 = nn.BatchNorm2d(num_features=256)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.bn5 = nn.BatchNorm2d(num_features=512)\n",
        "        \n",
        "        self.relu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=512*8*8, out_features=50)\n",
        "        ###########\n",
        "        ### HEXANET END\n",
        "        ###########\n",
        "      \n",
        "    def forward(self, x):\n",
        "                \n",
        "        ###########\n",
        "        ### HEXANET START\n",
        "        ###########\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.relu(self.bn5(self.conv5(x)))\n",
        "        x = x.view(x.shape[0], 512*8*8)\n",
        "        x = self.fc1(x)\n",
        "        ###########\n",
        "        ### HEXANET END\n",
        "        ###########\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        ###########\n",
        "        ### HEXANET START\n",
        "        ###########\n",
        "        self.fc1 = nn.Linear(in_features=50, out_features=512*8*8)\n",
        "        \n",
        "        self.conv5 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(num_features=256)\n",
        "\n",
        "        self.conv4 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=5, stride=2, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(num_features=128)\n",
        "\n",
        "\n",
        "        self.conv3 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=5, stride=2, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(num_features=64)\n",
        "        \n",
        "        self.conv2 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=5, stride=2, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(num_features=32)\n",
        "\n",
        "        self.conv1 = nn.ConvTranspose2d(in_channels=32, out_channels=1, kernel_size=6, stride=2, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        self.relu = nn.ReLU6()\n",
        "        \n",
        "        ###########\n",
        "        ### HEXANET END\n",
        "        ###########\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        ###########\n",
        "        ### HEXANET START\n",
        "        ###########\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(-1, 512, 8, 8)\n",
        "        x = self.relu(self.bn5(self.conv5(x)))\n",
        "        x = self.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.bn1(self.conv1(x))\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        ###########\n",
        "        ### HEXANET END\n",
        "        ###########\n",
        "\n",
        "        return x\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "for i in range(1):\n",
        "    encoder = Encoder(args)\n",
        "    decoder = Decoder(args)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    decoder = decoder.to(device)\n",
        "    encoder = encoder.to(device)\n",
        "\n",
        "    train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    criterion = criterion.to(device)\n",
        "    \n",
        "    # Here one has to specify where the above saved .txt-files will be saved\n",
        "    dec_x = np.loadtxt('/content/splinter_and_circle_256.txt') \n",
        "    dec_y = np.loadtxt('/content/splinter_and_circle_256_label.txt')\n",
        "    dec_x = dec_x.reshape(dec_x.shape[0],1,256,256)   \n",
        "\n",
        "    num_workers = 0\n",
        "\n",
        "    tensor_x = torch.Tensor(dec_x)\n",
        "    tensor_y = torch.tensor(dec_y,dtype=torch.long)\n",
        "    mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "    train_loader = torch.utils.data.DataLoader(mnist_bal, batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "\n",
        "    best_loss = np.inf\n",
        "\n",
        "    t0 = time.time()\n",
        "    if args['train']:\n",
        "        enc_optim = torch.optim.Adam(encoder.parameters(), lr = args['lr'], weight_decay = args['lambda'] )\n",
        "        dec_optim = torch.optim.Adam(decoder.parameters(), lr = args['lr'], weight_decay = args['lambda'])\n",
        "    \n",
        "        for epoch in range(args['epochs']):\n",
        "            train_loss = 0.0\n",
        "            tmse_loss = 0.0\n",
        "            tdiscr_loss = 0.0\n",
        "            encoder.train()\n",
        "            decoder.train()\n",
        "        \n",
        "            for images,labs in train_loader:\n",
        "                \n",
        "                encoder.zero_grad()\n",
        "                decoder.zero_grad()\n",
        "                images, labs = images.to(device), labs.to(device)\n",
        "                labsn = labs.detach().cpu().numpy()\n",
        "                z_hat = encoder(images)\n",
        "                x_hat = decoder(z_hat)\n",
        "                mse = criterion(x_hat,images)\n",
        "                          \n",
        "                resx = []\n",
        "                resy = []\n",
        "            \n",
        "                tc = np.random.choice(2,1)\n",
        "                \n",
        "                xbeg = dec_x[dec_y == tc]\n",
        "                ybeg = dec_y[dec_y == tc] \n",
        "                xlen = len(xbeg)\n",
        "                nsamp = min(xlen, 100)\n",
        "                ind = np.random.choice(list(range(len(xbeg))),nsamp,replace=False)\n",
        "                xclass = xbeg[ind]\n",
        "                yclass = ybeg[ind]\n",
        "            \n",
        "                xclen = len(xclass)\n",
        "                xcminus = np.arange(1,xclen)\n",
        "                \n",
        "                xcplus = np.append(xcminus,0)\n",
        "                xcnew = (xclass[[xcplus],:])\n",
        "                xcnew = xcnew.reshape(xcnew.shape[1],xcnew.shape[2],xcnew.shape[3],xcnew.shape[4])\n",
        "            \n",
        "                xcnew = torch.Tensor(xcnew)\n",
        "                xcnew = xcnew.to(device)\n",
        "            \n",
        "                xclass = torch.Tensor(xclass)\n",
        "                xclass = xclass.to(device)\n",
        "                xclass = encoder(xclass)\n",
        "            \n",
        "                xclass = xclass.detach().cpu().numpy()\n",
        "            \n",
        "                xc_enc = (xclass[[xcplus],:])\n",
        "                xc_enc = np.squeeze(xc_enc)\n",
        "            \n",
        "                xc_enc = torch.Tensor(xc_enc)\n",
        "                xc_enc = xc_enc.to(device)\n",
        "                \n",
        "                ximg = decoder(xc_enc)\n",
        "                \n",
        "                mse2 = criterion(ximg,xcnew)\n",
        "            \n",
        "                comb_loss = mse2 + mse\n",
        "                comb_loss.backward()\n",
        "\n",
        "                enc_optim.step()\n",
        "                dec_optim.step()\n",
        "            \n",
        "                train_loss += comb_loss.item()*images.size(0)\n",
        "                tmse_loss += mse.item()*images.size(0)\n",
        "                tdiscr_loss += mse2.item()*images.size(0)\n",
        "            \n",
        "                 \n",
        "            # print avg training statistics \n",
        "            train_loss = train_loss/len(train_loader)\n",
        "            tmse_loss = tmse_loss/len(train_loader)\n",
        "            tdiscr_loss = tdiscr_loss/len(train_loader)\n",
        "            print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
        "                    train_loss,tmse_loss,tdiscr_loss))\n",
        "            \n",
        "        \n",
        "        \n",
        "            #store the best encoder and decoder models\n",
        "            if train_loss < best_loss and train_loss < 0.1:\n",
        "                print('Saving..')\n",
        "                # Here one has to specify were the encoder and decoder models should be stored, as these are later used in the Generator block below\n",
        "                path_enc = '/content/DeepSMOTE_encoder.pth'\n",
        "                path_dec = '/content/DeepSMOTE_decoder.pth'\n",
        "             \n",
        "                torch.save(encoder.state_dict(), path_enc)\n",
        "                torch.save(decoder.state_dict(), path_dec)\n",
        "        \n",
        "                best_loss = train_loss\n",
        "              \n",
        "    t1 = time.time()\n",
        "    print('total time(min): {:.2f}'.format((t1 - t0)/60))             \n",
        " \n",
        "t4 = time.time()\n",
        "print('final time(min): {:.2f}'.format((t4 - t3)/60))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnE5X2v2ekWp"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import collections\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import os\n",
        "print(torch.version.cuda) #10.1\n",
        "import time\n",
        "from collections import Counter\n",
        "t0 = time.time()\n",
        "##############################################################################\n",
        "\"\"\"args for models\"\"\"\n",
        "\n",
        "args = {}\n",
        "args['lambda'] = 0.0001       # hyper param for weight decay\n",
        "args['lr'] = 0.0001           # learning rate for Adam optimizer \n",
        "args['epochs'] = 200          # how many epochs to run for (actually iterate till a train loss of ~0.05 is enough)\n",
        "args['batch_size'] = 4        # batch size for SGD\n",
        "args['train'] = True          # train networks if True, else load networks from\n",
        "\n",
        "##############################################################################\n",
        "\n",
        "## create encoder model and decoder model\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        ###########\n",
        "        ### HEXANET START\n",
        "        ###########\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=7, stride=2, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=32)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=2, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(num_features=64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(num_features=128)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.bn4 = nn.BatchNorm2d(num_features=256)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.bn5 = nn.BatchNorm2d(num_features=512)\n",
        "        \n",
        "        self.relu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=512*8*8, out_features=50)\n",
        "\n",
        "        ###########\n",
        "        ### HEXANET END\n",
        "        ###########\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        ###########\n",
        "        ### HEXANET START\n",
        "        ###########\n",
        "      \n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.relu(self.bn5(self.conv5(x)))\n",
        "        x = x.view(x.shape[0], 512*8*8)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        ###########\n",
        "        ### HEXANET END\n",
        "        ###########\n",
        "\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        ###########\n",
        "        ### HEXANET START\n",
        "        ###########\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=50, out_features=512*8*8)\n",
        "        \n",
        "        self.conv5 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(num_features=256)\n",
        "\n",
        "        self.conv4 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=5, stride=2, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(num_features=128)\n",
        "\n",
        "\n",
        "        self.conv3 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=5, stride=2, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(num_features=64)\n",
        "        \n",
        "        self.conv2 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=5, stride=2, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(num_features=32)\n",
        "\n",
        "        self.conv1 = nn.ConvTranspose2d(in_channels=32, out_channels=1, kernel_size=6, stride=2, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        self.relu = nn.ReLU6()\n",
        "        self.pool = nn.MaxUnpool2d(kernel_size=2)\n",
        "        \n",
        "        ###########\n",
        "        ### HEXANET END\n",
        "        ###########\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        ###########\n",
        "        ### HEXANET START\n",
        "        ###########\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(-1, 512, 8, 8)\n",
        "\n",
        "        x = self.relu(self.bn5(self.conv5(x)))\n",
        "        x = self.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.bn1(self.conv1(x))\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "\n",
        "        ###########\n",
        "        ### HEXANET END\n",
        "        ###########\n",
        "\n",
        "        return x\n",
        "   \n",
        "\n",
        "##############################################################################\n",
        "\n",
        "def biased_get_class1(c):\n",
        "    xbeg = dec_x[dec_y == c]\n",
        "    ybeg = dec_y[dec_y == c]\n",
        "    return xbeg, ybeg\n",
        "\n",
        "def G_SM1(X, y,n_to_sample,cl):\n",
        "\n",
        "    # n_neigh can be played around with\n",
        "    n_neigh = 5 + 1\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = X[base_indices]\n",
        "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "#############################################################################\n",
        "np.printoptions(precision=5,suppress=True)\n",
        "\n",
        "# DeepSMOTE normally would allow to use cross-validation during training and therefore uses 5 different files\n",
        "# For simplicity, we do not, and therefore hardcode the patch in this one-iteration loop\n",
        "for m in range(1):\n",
        "    dec_x = np.loadtxt('/content/drive/MyDrive/DViP/data/splinter_and_circle_256.txt') \n",
        "    dec_y = np.loadtxt('/content/drive/MyDrive/DViP/data/splinter_and_circle_256_label.txt')\n",
        "\n",
        "    print('train imgs before reshape ',dec_x.shape) \n",
        "    print('train labels ',dec_y.shape)\n",
        "\n",
        "    dec_x = dec_x.reshape(dec_x.shape[0],1,256,256)\n",
        "\n",
        "    print('train imgs after reshape ',dec_x.shape) #(45000,3,32,32)\n",
        "    \n",
        "    \n",
        "    train_on_gpu = torch.cuda.is_available()\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    \n",
        "    path_enc = '/content/DeepSMOTE_encoder.pth'\n",
        "    path_dec = '/content/DeepSMOTE_decoder.pth'\n",
        "\n",
        "    encoder = Encoder(args)\n",
        "    encoder.load_state_dict(torch.load(path_enc), strict=False)\n",
        "    encoder = encoder.to(device)\n",
        "\n",
        "    decoder = Decoder(args)\n",
        "    decoder.load_state_dict(torch.load(path_dec), strict=False)\n",
        "    decoder = decoder.to(device)\n",
        "\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    # Normally DeepSMOTE would calculate the imbalance between the classes automatically.\n",
        "    # As we achieved better results if the models are just trained on the class(es) that should be generated, we only use respective classes here.\n",
        "    dataset_distribution = Counter(dec_y)\n",
        "    #imbal = Counter(dec_y)\n",
        "    #imbal = [1096, 79]\n",
        "\n",
        "\n",
        "    resx = []\n",
        "    resy = [] \n",
        "\n",
        "    for i in range(0, len(dataset_distribution)):\n",
        "        xclass, yclass = biased_get_class1(i) \n",
        "        xclass = torch.Tensor(xclass)\n",
        "        xclass = xclass.to(device)\n",
        "        xclass = encoder(xclass)\n",
        "\n",
        "        xclass = xclass.detach().cpu().numpy()\n",
        "\n",
        "        # The standard DeepSMOTE code calculates the imbalance between classes by:\n",
        "        #n = dataset_distribution[max(dataset_distribution, key=dataset_distribution.get)] - dataset_distribution[i]\n",
        "        # We hardcoded \"658\" here, because in the train set there are 658 \"good\" images, so we want to generate the missing ones to balance the imbalance.\n",
        "        n = 658 - dataset_distribution[i]\n",
        "        print(\"Generate \", n, \" new images for class\", i)\n",
        "        print(len(xclass), len(yclass))\n",
        "        xsamp, ysamp = G_SM1(xclass,yclass,n,i)\n",
        "\n",
        "        ysamp = np.array(ysamp)\n",
        "    \n",
        "        xsamp = torch.Tensor(xsamp)\n",
        "        xsamp = xsamp.to(device)\n",
        "        ximg = decoder(xsamp)\n",
        "\n",
        "        ximn = ximg.detach().cpu().numpy()\n",
        "        resx.append(ximn)\n",
        "        resy.append(ysamp)\n",
        "\n",
        "    resx1 = np.vstack(resx)\n",
        "    resy1 = np.hstack(resy)\n",
        "    resx1 = resx1.reshape(resx1.shape[0],-1)\n",
        "    \n",
        "    # Normally, DeepSMOTE outputs the original images 'dec_x1' and the generated ones 'resx1'.\n",
        "    # This way, the output normally is a balanced image set.\n",
        "    # As we did not generate images for all classes and just for circle and splinter, we only want to output the generated ones seperately.\n",
        "    # Therefore, below we save \"resx1\" and \"resy1\" in the .txt-file instead of \"combx\" and \"comby\"\n",
        "    #dec_x1 = dec_x.reshape(dec_x.shape[0],-1)\n",
        "    #combx = np.vstack((resx1,dec_x1))\n",
        "    #comby = np.hstack((resy1,dec_y))\n",
        "\n",
        "\n",
        "    ifile = '/content/DeepSMOTE_dataset.txt'\n",
        "    np.savetxt(ifile, resx1)\n",
        "    \n",
        "    lfile = '/content/DeepSMOTE_dataset_labels.txt'\n",
        "    np.savetxt(lfile,resy1) \n",
        "    print()\n",
        "\n",
        "t1 = time.time()\n",
        "print('final time(min): {:.2f}'.format((t1 - t0)/60))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLdnFCZBFuLc"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "gen_imgs = np.loadtxt('/content/DeepSMOTE_dataset.txt')\n",
        "gen_imgs = gen_imgs.reshape(gen_imgs.shape[0],1,256,256)\n",
        "gen_labels = np.loadtxt('/content/DeepSMOTE_dataset_labels.txt')\n",
        "print(Counter(gen_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHicn-RI1Qt6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "gen_imgs = resx1.reshape(resx1.shape[0],1,256,256)\n",
        "gen_labels = resy1\n",
        "print(Counter(gen_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXfBMPEq1vZ8"
      },
      "source": [
        "# This codeblock is only used for debugging purposes to actually check how the generated images look.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def show_img(img_array, i):\n",
        "  img_array = img_array.reshape(256,256)\n",
        "  img = Image.fromarray(np.uint8(img_array * 255) , 'L')\n",
        "  # Uncomment the line below to save pictures in the specified path\n",
        "  #img.save('/content/drive/MyDrive/SampleGeneration/DeepSMOTE/Generated Images/circle/' + str(i) +'.png')\n",
        "  plt.imshow(img, interpolation='nearest', cmap='gray')\n",
        "  plt.show()\n",
        "for i in range(0, 1000):\n",
        "    show_img(gen_imgs[i].astype(np.uint8), i)\n",
        "    print(resy1[i])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}